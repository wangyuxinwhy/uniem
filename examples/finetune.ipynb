{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å¾®è°ƒ M3E\n",
    "\n",
    "ğŸ‘ğŸ» æ¬¢è¿æ¥åˆ° M3E çš„å¾®è°ƒæ•™ç¨‹ï¼Œåœ¨è¿™é‡Œæ‚¨å°†å­¦ä¹ åˆ°å¦‚ä½•ä½¿ç”¨ uniem åº“æä¾›çš„ `FineTuner` å¯¹ M3E æ¨¡å‹è¿›è¡Œå¾®è°ƒã€‚å¦‚æœæ‚¨æ˜¯åœ¨ colab ç¯å¢ƒä¸­è¿è¡Œï¼Œè¯·ä½¿ç”¨ GPU è¿è¡Œæ—¶ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æœ€å¼€å§‹è‚¯å®šæ˜¯å®‰è£… `uniem` åº“äº† ğŸ˜‰\n",
    "!pip install uniem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`uniem` å·²ç»å®‰è£…å®Œæˆäº†ï¼Œè®©å…ˆçœ‹ä¸€ä¸ªç®€å•çš„ä¾‹å­ï¼Œæ¥æ„Ÿå—ä¸€ä¸‹å¾®è°ƒçš„è¿‡ç¨‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "dataset = load_dataset('shibing624/nli_zh', 'STS-B')\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=dataset)\n",
    "finetuner.run(epochs=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ å¾®è°ƒå·²ç»å®Œæˆäº†ï¼Œé€šè¿‡ `FineTuner` æˆ‘ä»¬åªéœ€è¦å‡ è¡Œä»£ç å°±å¯ä»¥å®Œæˆå¾®è°ƒï¼Œå°±åƒé­”æ³•ä¸€æ ·ï¼\n",
    "\n",
    "è®©æˆ‘ä»¬çœ‹çœ‹è¿™èƒŒåå‘ç”Ÿäº†ä»€ä¹ˆï¼Œä¸ºä»€ä¹ˆå¯ä»¥è¿™ä¹ˆç®€å•ï¼Ÿ\n",
    "\n",
    "1. `FineTuner` ä¼šè‡ªåŠ¨åŠ è½½ M3E æ¨¡å‹ï¼Œæ‚¨åªéœ€è¦å£°æ˜å³å¯ï¼Œå°±åƒä¾‹å­ä¸­çš„ `moka-ai/m3e-small`\n",
    "2. `FineTuner` ä¼šè‡ªåŠ¨è¯†åˆ«æ•°æ®æ ¼å¼ï¼Œåªè¦æ‚¨çš„æ•°æ®ç±»å‹åœ¨ `FineTuner` æ”¯æŒçš„èŒƒå›´å†…ï¼Œ`FineTuner` å°±ä¼šè‡ªåŠ¨è¯†åˆ«å¹¶åŠ ä»¥ä½¿ç”¨\n",
    "3. `FineTuner` ä¼šè‡ªåŠ¨é€‰æ‹©è®­ç»ƒæ–¹å¼ï¼Œ`FineTuner` ä¼šæ ¹æ®æ¨¡å‹å’Œæ•°æ®é›†è‡ªåŠ¨åœ°é€‰æ‹©è®­ç»ƒæ–¹å¼ï¼Œå³ å¯¹æ¯”å­¦ä¹  æˆ–è€… CoSent ç­‰\n",
    "4. `FineTuner` ä¼šè‡ªåŠ¨é€‰æ‹©è®­ç»ƒç¯å¢ƒå’Œè¶…å‚æ•°ï¼Œ`FineTuner` ä¼šæ ¹æ®æ‚¨çš„ç¡¬ä»¶ç¯å¢ƒè‡ªåŠ¨é€‰æ‹©è®­ç»ƒè®¾å¤‡ï¼Œå¹¶æ ¹æ®æ¨¡å‹ã€æ•°æ®ç­‰å„ç§ä¿¡æ¯è‡ªåŠ¨å»ºè®®æœ€ä½³çš„è¶…å‚æ•°ï¼Œlr, batch_size ç­‰ï¼Œå½“ç„¶æ‚¨ä¹Ÿå¯ä»¥è‡ªå·±æ‰‹åŠ¨è¿›è¡Œè°ƒæ•´\n",
    "5. `FineTuner` ä¼šè‡ªåŠ¨ä¿å­˜å¾®è°ƒè®°å½•å’Œæ¨¡å‹ï¼Œ`FineTuner` ä¼šæ ¹æ®æ‚¨çš„è®¾ç½®è‡ªåŠ¨ä½¿ç”¨æ‚¨ç¯å¢ƒä¸­çš„ wandb, tensorboard ç­‰æ¥è®°å½•å¾®è°ƒè¿‡ç¨‹ï¼ŒåŒæ—¶ä¹Ÿä¼šè‡ªåŠ¨ä¿å­˜å¾®è°ƒæ¨¡å‹\n",
    "\n",
    "æ€»ç»“ä¸€ä¸‹ï¼Œ`FineTuner` ä¼šè‡ªåŠ¨å®Œæˆå¾®è°ƒæ‰€éœ€çš„å„ç§å·¥ä½œï¼Œåªè¦æ‚¨çš„æ•°æ®ç±»å‹åœ¨ `FineTuner` æ”¯æŒçš„èŒƒå›´å†…ï¼\n",
    "\n",
    "é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬çœ‹çœ‹ `FineTuner` éƒ½æ”¯æŒå“ªäº›ç±»å‹çš„æ•°æ®å§ã€‚"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FineTuner æ”¯æŒçš„æ•°æ®ç±»å‹\n",
    "\n",
    "`FineTuner` ä¸­ `dataset` å‚æ•°æ˜¯ä¸€ä¸ªå¯ä¾›è¿­ä»£ (for å¾ªç¯) çš„æ•°æ®é›†ï¼Œæ¯æ¬¡è¿­ä»£ä¼šè¿”å›ä¸€ä¸ªæ ·æœ¬ï¼Œè¿™ä¸ªæ ·æœ¬åº”è¯¥æ˜¯ä»¥ä¸‹ä¸‰ç§æ ¼å¼ä¹‹ä¸€ï¼š\n",
    "\n",
    "1. `PairRecord`ï¼Œå¥å¯¹æ ·æœ¬\n",
    "2. `TripletRecord`ï¼Œå¥å­ä¸‰å…ƒç»„æ ·æœ¬\n",
    "3. `ScoredPairRecord`ï¼Œå¸¦æœ‰åˆ†æ•°çš„å¥å¯¹æ ·æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "from uniem.data_structures import RecordType, PairRecord, TripletRecord, ScoredPairRecord\n",
    "\n",
    "os.environ['TOKENIZERS_PARALLELISM'] = 'false'\n",
    "warnings.filterwarnings('ignore')\n",
    "print(f'record_types: {[record_type.value for record_type in RecordType]}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PairRecord\n",
    "\n",
    "`PairRecord` å°±æ˜¯å¥å¯¹æ ·æœ¬ï¼Œæ¯ä¸€ä¸ªæ ·æœ¬éƒ½ä»£è¡¨ä¸€å¯¹ç›¸ä¼¼çš„å¥å­ï¼Œå­—æ®µçš„åç§°æ˜¯ `text` å’Œ `text_pos`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_record = PairRecord(text='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', text_pos='å¦‚ä½•æ²»æ„ˆè‚¾ç»“çŸ³')\n",
    "print(f'pair_record: {pair_record}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TripletRecord\n",
    "\n",
    "`TripletRecord` å°±æ˜¯å¥å­ä¸‰å…ƒç»„æ ·æœ¬ï¼Œåœ¨ `PairRecord` çš„åŸºç¡€ä¸Šå¢åŠ äº†ä¸€ä¸ªä¸ç›¸ä¼¼å¥å­è´Ÿä¾‹ï¼Œå­—æ®µçš„åç§°æ˜¯ `text`ã€`text_pos` å’Œ `text_neg`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_record = TripletRecord(text='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', text_pos='å¦‚ä½•æ²»æ„ˆè‚¾ç»“çŸ³', text_neg='èƒ†ç»“çŸ³æœ‰å“ªäº›æ²»ç–—æ–¹æ³•ï¼Ÿ')\n",
    "print(f'triplet_record: {triplet_record}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ScoredPairRecord\n",
    "\n",
    "`ScoredPairRecord` å°±æ˜¯å¸¦æœ‰åˆ†æ•°çš„å¥å¯¹æ ·æœ¬ï¼Œåœ¨ `PairRecord` çš„åŸºç¡€ä¸Šæ·»åŠ äº†å¥å¯¹çš„ç›¸ä¼¼åˆ†æ•°(ç¨‹åº¦)ã€‚å­—æ®µçš„åç§°æ˜¯ `sentence1` å’Œ `sentence2`ï¼Œä»¥åŠ `label`ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.0 ä»£è¡¨ç›¸ä¼¼ï¼Œ0.0 ä»£è¡¨ä¸ç›¸ä¼¼\n",
    "scored_pair_record1 = ScoredPairRecord(sentence1='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', sentence2='å¦‚ä½•æ²»æ„ˆè‚¾ç»“çŸ³', label=1.0)\n",
    "scored_pair_record2 = ScoredPairRecord(sentence1='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', sentence2='èƒ†ç»“çŸ³æœ‰å“ªäº›æ²»ç–—æ–¹æ³•ï¼Ÿ', label=0.0)\n",
    "print(f'scored_pair_record: {scored_pair_record1}')\n",
    "print(f'scored_pair_record: {scored_pair_record2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.0 ä»£è¡¨ç›¸ä¼¼ï¼Œ1.0 ä»£è¡¨éƒ¨åˆ†ç›¸ä¼¼ï¼Œ0.0 ä»£è¡¨ä¸ç›¸ä¼¼\n",
    "scored_pair_record1 = ScoredPairRecord(sentence1='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', sentence2='å¦‚ä½•æ²»æ„ˆè‚¾ç»“çŸ³', label=2.0)\n",
    "scored_pair_record2 = ScoredPairRecord(sentence1='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', sentence2='èƒ†ç»“çŸ³æœ‰å“ªäº›æ²»ç–—æ–¹æ³•ï¼Ÿ', label=1.0)\n",
    "scored_pair_record3 = ScoredPairRecord(sentence1='è‚¾ç»“çŸ³å¦‚ä½•æ²»ç–—ï¼Ÿ', sentence2='å¤±çœ å¦‚ä½•æ²»ç–—', label=0)\n",
    "print(f'scored_pair_record: {scored_pair_record1}')\n",
    "print(f'scored_pair_record: {scored_pair_record2}')\n",
    "print(f'scored_pair_record: {scored_pair_record3}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### å°ç»“\n",
    "\n",
    "`FineTuner` æ”¯æŒçš„æ•°æ®ç±»å‹æœ‰ä¸‰ç§ï¼Œåˆ†åˆ«æ˜¯ `PairRecord`ï¼Œ`TripletRecord` å’Œ `ScoredPairRecord`ï¼Œå…¶ä¸­ `TripletRecord` æ¯” `PairRecord` å¤šäº†ä¸€ä¸ªä¸ç›¸ä¼¼å¥å­è´Ÿä¾‹ï¼Œè€Œ `ScoredPairRecord` æ˜¯åœ¨ `PairRecord` çš„åŸºç¡€ä¸Šæ·»åŠ äº†å¥å¯¹çš„ç›¸ä¼¼åˆ†æ•°ã€‚\n",
    "\n",
    "åªè¦æ‚¨çš„æ•°æ®é›†æ˜¯è¿™ä¸‰ç§ç±»å‹ä¹‹ä¸€ï¼Œ`FineTuner` å°±å¯ä»¥è‡ªåŠ¨è¯†åˆ«å¹¶ä½¿ç”¨ã€‚ç°åœ¨è®©æˆ‘ä»¬çœ‹çœ‹å®é™…çš„ä¾‹å­"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¤ºä¾‹ï¼šåŒ»ç–—ç›¸ä¼¼é—®é¢˜\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬å‡è®¾æˆ‘ä»¬æƒ³è¦ HuggingFace ä¸Šæ‰˜ç®¡çš„ vegaviazhang/Med_QQpairs åŒ»ç–—æ•°æ®é›†ä¸Šåšå¾®è°ƒï¼Œè®©æˆ‘ä»¬å…ˆæŠŠæ•°æ®é›†ä¸‹è½½å¥½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "med_dataset_dict = load_dataset('vegaviazhang/Med_QQpairs')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®©æˆ‘ä»¬æŸ¥çœ‹ä¸€ä¸‹ Med_QQpairs çš„æ•°æ®æ ¼å¼æ˜¯ä¸æ˜¯åœ¨ `FineTuner` æ”¯æŒçš„èŒƒå›´å†…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(med_dataset_dict['train'][0])\n",
    "print(med_dataset_dict['train'][1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "æˆ‘ä»¬å‘ç° Med_QQpairs æ•°æ®é›†æ­£å¥½ç¬¦åˆæˆ‘ä»¬ `ScoredPairRecord` çš„æ•°æ®æ ¼å¼ï¼Œåªæ˜¯å­—æ®µåç§°æ˜¯ `question1` å’Œ `question2`ï¼Œæˆ‘ä»¬åªéœ€è¦ä¿®æ”¹æˆ `sentence1` å’Œ `sentence2` å°±å¯ä»¥ç›´æ¥è¿›è¡Œå¾®è°ƒäº†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "dataset = load_dataset('vegaviazhang/Med_QQpairs')\n",
    "dataset = dataset.rename_columns({'question1': 'sentence1', 'question2': 'sentence2'})\n",
    "# æŒ‡å®šè®­ç»ƒçš„æ¨¡å‹ä¸º m3e-small\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=dataset)\n",
    "finetuner.run(epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è®­ç»ƒè¿‡ç¨‹å®Œæˆåï¼Œä¼šè‡ªåŠ¨ä¿å­˜æ¨¡å‹åˆ° finetuned-model ç›®å½•ä¸‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls finetuned-model/model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¤ºä¾‹ï¼šçŒœè°œ\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬è¦å¯¹ä¸€ä¸ªçŒœè°œçš„æ•°æ®é›†è¿›è¡Œå¾®è°ƒï¼Œè¿™ä¸ªæ•°æ®é›†æ˜¯é€šè¿‡ json line çš„å½¢å¼å­˜å‚¨çš„ï¼Œè®©æˆ‘å…ˆçœ‹çœ‹æ•°æ®æ ¼å¼å§ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_json('example_data/riddle.jsonl', lines=True)\n",
    "records = df.to_dict('records')\n",
    "print(records[0])\n",
    "print(records[1])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è¿™ä¸ªæ•°æ®é›†ä¸­ï¼Œæˆ‘ä»¬æœ‰ `instruction` å’Œ `output` ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠè¿™ä¸¤è€…çœ‹æˆä¸€ä¸ªç›¸ä¼¼å¥å¯¹ã€‚è¿™æ˜¯ä¸€ä¸ªå…¸å‹çš„ `PairRecord` æ•°æ®é›†ã€‚\n",
    "\n",
    "`PairRecord` éœ€è¦ `text` å’Œ `text_pos` ä¸¤ä¸ªå­—æ®µï¼Œå› æ­¤æˆ‘ä»¬éœ€è¦å¯¹æ•°æ®é›†çš„å­—æ®µè¿›è¡Œé‡æ–°å‘½åï¼Œä»¥ç¬¦åˆ `PairRecord` çš„æ ¼å¼ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from uniem.finetuner import FineTuner\n",
    "\n",
    "# è¯»å– jsonl æ–‡ä»¶\n",
    "df = pd.read_json('example_data/riddle.jsonl', lines=True)\n",
    "# é‡æ–°å‘½å\n",
    "df = df.rename(columns={'instruction': 'text', 'output': 'text_pos'})\n",
    "# æŒ‡å®šè®­ç»ƒçš„æ¨¡å‹ä¸º m3e-small\n",
    "finetuner = FineTuner('moka-ai/m3e-small', dataset=df.to_dict('records'))\n",
    "finetuner.run(epochs=1, output_dir='finetuned-model-riddle')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ä¸Šé¢çš„ä¸¤ä¸ªç¤ºä¾‹åˆ†åˆ«å±•ç¤ºäº†å¯¹ jsonl æœ¬åœ° `PairRecord` ç±»å‹æ•°æ®é›†ï¼Œä»¥åŠ huggingface è¿œç¨‹ `ScoredPair` ç±»å‹æ•°æ®é›†çš„è¯»å–å’Œè®­ç»ƒè¿‡ç¨‹ã€‚`TripletRecord` ç±»å‹çš„æ•°æ®é›†çš„è¯»å–å’Œè®­ç»ƒè¿‡ç¨‹ä¸ `PairRecord` ç±»å‹çš„æ•°æ®é›†çš„è¯»å–å’Œè®­ç»ƒè¿‡ç¨‹ç±»ä¼¼ï¼Œè¿™é‡Œå°±ä¸å†èµ˜è¿°äº†ã€‚\n",
    "\n",
    "ä¹Ÿå°±æ˜¯è¯´ï¼Œä½ åªè¦æ„é€ äº†ç¬¦åˆ `uniem` æ”¯æŒçš„æ•°æ®æ ¼å¼çš„æ•°æ®é›†ï¼Œå°±å¯ä»¥ä½¿ç”¨ `FineTuner` å¯¹ä½ çš„æ¨¡å‹è¿›è¡Œå¾®è°ƒäº†ã€‚\n",
    "\n",
    "`FineTuner` æ¥å—çš„ dataset å‚æ•°ï¼Œåªè¦æ˜¯å¯ä»¥è¿­ä»£çš„äº§ç”Ÿæœ‰æŒ‡å®šæ ¼å¼çš„å­—å…¸ `dict` å°±è¡Œäº†ï¼Œæ‰€ä»¥ä¸Šè¿°ç¤ºä¾‹åˆ†åˆ«ä½¿ç”¨ `datasets.DatasetDict` å’Œ `list[dict]` ä¸¤ç§æ•°æ®æ ¼å¼ã€‚"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uniem",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
